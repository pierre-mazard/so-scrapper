#!/usr/bin/env python3
"""
Script utilitaire pour mettre √† jour TOUTE la base de donn√©es Stack Overflow.

Ce script r√©cup√®re toutes les questions existantes en base et les met √† jour
via l'API Stack Overflow avec les derni√®res informations (scores, r√©ponses, etc.).

Usage:
    python utils/update_all_database.py
    
Options:
    --batch-size: Nombre de questions √† traiter par batch (d√©faut: 100)
    --dry-run: Mode test sans modification de la base
    --max-questions: Limite le nombre de questions √† mettre √† jour
    --delay: D√©lai entre les requ√™tes API en secondes (d√©faut: 0.1)
"""

import sys
import os
import asyncio
import argparse
import logging
from datetime import datetime
from typing import List, Dict, Any
import time

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import Config
from src.database import DatabaseManager
from src.scraper import StackOverflowScraper
from src.analyzer import DataAnalyzer

class DatabaseUpdater:
    def __init__(self, config: Config, dry_run: bool = False):
        self.config = config
        self.dry_run = dry_run
        self.db_manager = None
        self.scraper = None
        self.logger = self._setup_logger()
        
        # Statistiques
        self.stats = {
            'total_questions': 0,
            'processed': 0,
            'updated': 0,
            'errors': 0,
            'skipped': 0,
            'authors_updated': 0,
            'start_time': None,
            'batches_completed': 0
        }
    
    def _setup_logger(self) -> logging.Logger:
        """Configure le logger pour l'update."""
        logger = logging.getLogger('database_updater')
        logger.setLevel(logging.INFO)
        
        # Handler pour la console
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
        
        # Handler pour fichier
        log_file = f"logs/database_update_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        os.makedirs('logs', exist_ok=True)
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(console_formatter)
        logger.addHandler(file_handler)
        
        return logger
    
    async def initialize(self):
        """Initialise les composants n√©cessaires."""
        self.logger.info("[INIT] Initialisation du syst√®me de mise √† jour...")
        
        # Initialiser la base de donn√©es
        self.db_manager = DatabaseManager(self.config.database_config)
        await self.db_manager.connect()
        self.logger.info("[OK] Connexion √† la base de donn√©es √©tablie")
        
        # Initialiser le scraper
        self.scraper = StackOverflowScraper(self.config)
        await self.scraper.setup_session()
        self.logger.info("[OK] Scraper Stack Overflow initialis√©")
        
        if self.dry_run:
            self.logger.info("[DRY-RUN] MODE DRY-RUN : Aucune modification ne sera apport√©e √† la base")
    
    async def get_all_question_ids(self) -> List[int]:
        """R√©cup√®re tous les IDs des questions en base."""
        self.logger.info("[LIST] R√©cup√©ration de la liste des questions en base...")
        
        questions_collection = self.db_manager.motor_database[self.db_manager.questions_collection]
        cursor = questions_collection.find({}, {"question_id": 1})
        
        question_ids = []
        async for doc in cursor:
            question_ids.append(doc["question_id"])
        
        self.stats['total_questions'] = len(question_ids)
        self.logger.info(f"[STATS] {len(question_ids)} questions trouv√©es en base de donn√©es")
        
        return question_ids
    
    async def update_questions_batch(self, question_ids: List[int], batch_num: int, total_batches: int) -> Dict[str, int]:
        """Met √† jour un batch de questions."""
        batch_size = len(question_ids)
        self.logger.info(f"[BATCH] Batch {batch_num}/{total_batches} : Mise √† jour de {batch_size} questions...")
        
        batch_stats = {
            'updated': 0,
            'errors': 0,
            'skipped': 0,
            'authors_updated': 0
        }
        
        try:
            # R√©cup√©rer les donn√©es via l'API Stack Overflow
            questions_data = await self.scraper.get_questions_by_ids(question_ids)
            
            if not questions_data:
                self.logger.warning(f"[WARNING] Aucune donn√©e r√©cup√©r√©e pour ce batch")
                batch_stats['skipped'] = batch_size
                return batch_stats
            
            self.logger.info(f"[API] {len(questions_data)} questions r√©cup√©r√©es de l'API")
            
            # Mettre √† jour en base si pas en mode dry-run
            if not self.dry_run:
                # Mettre √† jour les questions
                storage_result = await self.db_manager.store_questions(
                    questions_data, 
                    update_only=True
                )
                
                batch_stats['updated'] = storage_result['questions_stored']
                batch_stats['authors_updated'] = storage_result.get('authors_new', 0) + storage_result.get('authors_updated', 0)
                
                self.logger.info(f"[OK] {batch_stats['updated']} questions mises √† jour")
                if batch_stats['authors_updated'] > 0:
                    self.logger.info(f"[AUTHORS] {batch_stats['authors_updated']} auteurs mis √† jour")
            else:
                # Mode dry-run : simuler la mise √† jour
                batch_stats['updated'] = len(questions_data)
                self.logger.info(f"[DRY-RUN] {batch_stats['updated']} questions seraient mises √† jour")
            
        except Exception as e:
            self.logger.error(f"[ERROR] Erreur lors de la mise √† jour du batch {batch_num}: {e}")
            batch_stats['errors'] = batch_size
        
        return batch_stats
    
    async def update_all_database(self, batch_size: int = 100, max_questions: int = None, delay: float = 0.1):
        """Met √† jour toute la base de donn√©es."""
        self.stats['start_time'] = time.time()
        
        self.logger.info("=" * 80)
        self.logger.info("[UPDATE] D√âBUT DE LA MISE √Ä JOUR COMPL√àTE DE LA BASE DE DONN√âES")
        self.logger.info("=" * 80)
        
        # R√©cup√©rer tous les IDs de questions
        all_question_ids = await self.get_all_question_ids()
        
        if not all_question_ids:
            self.logger.warning("[WARNING] Aucune question trouv√©e en base de donn√©es")
            return
        
        # Limiter si demand√©
        if max_questions and max_questions < len(all_question_ids):
            all_question_ids = all_question_ids[:max_questions]
            self.logger.info(f"üéØ Limitation √† {max_questions} questions")
        
        # Cr√©er les batches
        total_questions = len(all_question_ids)
        batches = [all_question_ids[i:i + batch_size] for i in range(0, total_questions, batch_size)]
        total_batches = len(batches)
        
        self.logger.info(f"üì¶ {total_batches} batches de {batch_size} questions maximum")
        self.logger.info(f"‚è±Ô∏è  D√©lai entre requ√™tes: {delay}s")
        
        # Traiter chaque batch
        for i, batch_ids in enumerate(batches, 1):
            batch_stats = await self.update_questions_batch(batch_ids, i, total_batches)
            
            # Mettre √† jour les statistiques globales
            self.stats['processed'] += len(batch_ids)
            self.stats['updated'] += batch_stats['updated']
            self.stats['errors'] += batch_stats['errors']
            self.stats['skipped'] += batch_stats['skipped']
            self.stats['authors_updated'] += batch_stats['authors_updated']
            self.stats['batches_completed'] += 1
            
            # Afficher le progr√®s
            progress = (i / total_batches) * 100
            self.logger.info(f"üìà Progression: {progress:.1f}% ({i}/{total_batches} batches)")
            
            # D√©lai entre les batches pour respecter les limites de l'API
            if i < total_batches and delay > 0:
                await asyncio.sleep(delay)
        
        # Afficher le r√©sum√© final
        await self._display_final_summary()
        
        # G√©n√©rer le rapport de mise √† jour
        await self.generate_update_report()
    
    async def _display_final_summary(self):
        """Affiche le r√©sum√© final de la mise √† jour."""
        elapsed_time = time.time() - self.stats['start_time']
        
        self.logger.info("=" * 80)
        self.logger.info("üìä R√âSUM√â FINAL DE LA MISE √Ä JOUR")
        self.logger.info("=" * 80)
        self.logger.info(f"‚è±Ô∏è  Dur√©e totale: {elapsed_time:.1f}s")
        self.logger.info(f"üìã Questions en base: {self.stats['total_questions']}")
        self.logger.info(f"üîÑ Questions trait√©es: {self.stats['processed']}")
        self.logger.info(f"‚úÖ Questions mises √† jour: {self.stats['updated']}")
        self.logger.info(f"üë§ Auteurs mis √† jour: {self.stats['authors_updated']}")
        self.logger.info(f"‚ö†Ô∏è  Erreurs: {self.stats['errors']}")
        self.logger.info(f"‚è≠Ô∏è  Ignor√©es: {self.stats['skipped']}")
        self.logger.info(f"üì¶ Batches compl√©t√©s: {self.stats['batches_completed']}")
        
        if self.stats['processed'] > 0:
            success_rate = (self.stats['updated'] / self.stats['processed']) * 100
            questions_per_sec = self.stats['processed'] / elapsed_time
            self.logger.info(f"üìà Taux de succ√®s: {success_rate:.1f}%")
            self.logger.info(f"‚ö° Vitesse: {questions_per_sec:.1f} questions/sec")
        
        if self.dry_run:
            self.logger.info("üß™ MODE DRY-RUN: Aucune modification r√©elle n'a √©t√© apport√©e")
        else:
            self.logger.info("üéâ MISE √Ä JOUR TERMIN√âE AVEC SUCC√àS!")
    
    async def generate_update_report(self):
        """G√©n√®re un rapport de mise √† jour dans le dossier reports."""
        try:
            self.logger.info("üìÑ G√©n√©ration du rapport de mise √† jour...")
            
            # Cr√©er le dossier reports s'il n'existe pas
            os.makedirs('output/reports', exist_ok=True)
            
            # Timestamp pour le nom du fichier
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_file = f"output/reports/database_update_report_{timestamp}.md"
            
            # Calculer les statistiques finales
            elapsed_time = time.time() - self.stats['start_time']
            success_rate = (self.stats['updated'] / self.stats['processed']) * 100 if self.stats['processed'] > 0 else 0
            questions_per_sec = self.stats['processed'] / elapsed_time if elapsed_time > 0 else 0
            
            # Contenu du rapport
            report_content = f"""# üìä RAPPORT DE MISE √Ä JOUR - BASE DE DONN√âES STACK OVERFLOW

*Rapport de mise √† jour compl√®te de la base de donn√©es*

---

## üöÄ INFORMATIONS D'EX√âCUTION

### Configuration de la mise √† jour

- **Date de d√©marrage**: {datetime.fromtimestamp(self.stats['start_time']).strftime('%Y-%m-%d %H:%M:%S')}
- **Mode d'ex√©cution**: {"üß™ DRY-RUN (test)" if self.dry_run else "üîÑ MISE √Ä JOUR R√âELLE"}
- **Dur√©e totale**: {elapsed_time:.1f} secondes

---

## üìä STATISTIQUES GLOBALES

### Questions trait√©es

| M√©trique | Valeur |
|----------|--------|
| **Questions en base de donn√©es** | {self.stats['total_questions']:,} |
| **Questions trait√©es** | {self.stats['processed']:,} |
| **Questions mises √† jour** | {self.stats['updated']:,} |
| **Erreurs rencontr√©es** | {self.stats['errors']:,} |
| **Questions ignor√©es** | {self.stats['skipped']:,} |

### Auteurs

- **Auteurs mis √† jour**: {self.stats['authors_updated']:,}

### Performance

| M√©trique | Valeur |
|----------|--------|
| **Batches compl√©t√©s** | {self.stats['batches_completed']:,} |
| **Taux de succ√®s** | {success_rate:.1f}% |
| **Vitesse de traitement** | {questions_per_sec:.1f} questions/sec |

---

## üîÑ D√âTAILS DE L'OP√âRATION

### Processus de mise √† jour

1. **üìã R√©cup√©ration des IDs**: Extraction de tous les IDs de questions en base
2. **üì¶ Division en batches**: Organisation des questions par lots pour traitement
3. **üì° R√©cup√©ration API**: R√©cup√©ration des donn√©es via l'API Stack Overflow
4. **üíæ Mise √† jour base**: {"Simulation des mises √† jour" if self.dry_run else "Application des mises √† jour en base de donn√©es"}

### R√©sultats par cat√©gorie

- **‚úÖ Questions mises √† jour avec succ√®s**: {self.stats['updated']:,}
- **‚ö†Ô∏è Questions avec erreurs**: {self.stats['errors']:,}
- **‚è≠Ô∏è Questions ignor√©es (API)**: {self.stats['skipped']:,}

---

## üìà ANALYSE DE PERFORMANCE

### Efficacit√© du processus

- **Taux de traitement r√©ussi**: {success_rate:.1f}%
- **Questions par seconde**: {questions_per_sec:.1f}
- **Temps moyen par question**: {(elapsed_time / self.stats['processed']) * 1000:.1f}ms

### R√©partition des r√©sultats

- **Succ√®s**: {(self.stats['updated'] / self.stats['processed'] * 100) if self.stats['processed'] > 0 else 0:.1f}%
- **Erreurs**: {(self.stats['errors'] / self.stats['processed'] * 100) if self.stats['processed'] > 0 else 0:.1f}%
- **Ignor√©es**: {(self.stats['skipped'] / self.stats['processed'] * 100) if self.stats['processed'] > 0 else 0:.1f}%

---

## üí° RECOMMANDATIONS

### Optimisations possibles

"""

            # Ajouter des recommandations bas√©es sur les r√©sultats
            if self.stats['errors'] > 0:
                error_rate = (self.stats['errors'] / self.stats['processed']) * 100
                if error_rate > 10:
                    report_content += f"- ‚ö†Ô∏è **Taux d'erreur √©lev√© ({error_rate:.1f}%)**: V√©rifier les limitations de l'API et la connectivit√©\n"
                else:
                    report_content += f"- ‚úÖ **Taux d'erreur acceptable ({error_rate:.1f}%)**\n"

            if questions_per_sec < 1:
                report_content += "- üêå **Performance lente**: Consid√©rer augmenter les d√©lais ou r√©duire la taille des batches\n"
            elif questions_per_sec > 10:
                report_content += "- ‚ö° **Excellente performance**: Le syst√®me fonctionne de mani√®re optimale\n"
            else:
                report_content += "- üëç **Performance correcte**: Le syst√®me fonctionne normalement\n"

            if self.stats['skipped'] > self.stats['updated']:
                report_content += "- üì° **Beaucoup de questions ignor√©es**: V√©rifier la disponibilit√© des donn√©es via l'API\n"

            # Finaliser le rapport
            report_content += f"""
### Actions suivantes recommand√©es

{"- üß™ **Ex√©cuter en mode r√©el**: Ce test montre que le processus est pr√™t" if self.dry_run else "- ‚úÖ **Mise √† jour termin√©e**: Base de donn√©es synchronis√©e avec succ√®s"}
- üìä **Analyser les donn√©es**: Lancer une analyse compl√®te des donn√©es mises √† jour
- üîÑ **Planifier la prochaine mise √† jour**: √âtablir une fr√©quence de mise √† jour r√©guli√®re

---

## üìã JOURNAL D'EX√âCUTION

### Configuration utilis√©e

- **Taille des batches**: Optimis√©e pour l'API Stack Overflow
- **D√©lais entre requ√™tes**: Respect des limitations de taux
- **Gestion des erreurs**: R√©cup√©ration automatique et logging d√©taill√©

### Fichiers g√©n√©r√©s

- **Log d√©taill√©**: `logs/database_update_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log`
- **Rapport de mise √† jour**: `{report_file}`

---

**Rapport g√©n√©r√© le {datetime.now().strftime('%Y-%m-%d √† %H:%M:%S')}**
*Utilitaire de mise √† jour de base de donn√©es - Stack Overflow Scraper*
"""

            # √âcrire le rapport
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"üìÑ Rapport de mise √† jour g√©n√©r√©: {report_file}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la g√©n√©ration du rapport: {e}")
    
    async def cleanup(self):
        """Nettoie les ressources."""
        if self.scraper:
            await self.scraper.close()
        if self.db_manager:
            await self.db_manager.disconnect()
        self.logger.info("[CLEANUP] Toutes les connexions ferm√©es")

async def main():
    """Fonction principale."""
    parser = argparse.ArgumentParser(
        description="Met √† jour toute la base de donn√©es Stack Overflow avec les derni√®res informations."
    )
    parser.add_argument(
        '--batch-size', 
        type=int, 
        default=100,
        help='Nombre de questions √† traiter par batch (d√©faut: 100)'
    )
    parser.add_argument(
        '--dry-run', 
        action='store_true',
        help='Mode test sans modification de la base'
    )
    parser.add_argument(
        '--max-questions', 
        type=int,
        help='Limite le nombre de questions √† mettre √† jour'
    )
    parser.add_argument(
        '--delay', 
        type=float, 
        default=0.1,
        help='D√©lai entre les requ√™tes API en secondes (d√©faut: 0.1)'
    )
    
    args = parser.parse_args()
    
    try:
        # Charger la configuration
        config = Config()
        
        # Cr√©er l'updater
        updater = DatabaseUpdater(config, dry_run=args.dry_run)
        
        # Initialiser
        await updater.initialize()
        
        # Lancer la mise √† jour
        await updater.update_all_database(
            batch_size=args.batch_size,
            max_questions=args.max_questions,
            delay=args.delay
        )
        
    except KeyboardInterrupt:
        print("\n‚è∏Ô∏è  Mise √† jour interrompue par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        return 1
    finally:
        if 'updater' in locals():
            await updater.cleanup()
    
    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
