# üîç Stack Overflow Scraper & Analyzer

Un outil complet d'extraction et d'analyse de donn√©es Stack Overflow avec support dual (Web Scraping + API) et syst√®me d'analyse avanc√©.

## üìã Table des mati√®res

- [Vue d'ensemble](#-vue-densemble)
- [Fonctionnement Complet du Pipeline](#-fonctionnement-complet-du-pipeline)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Installation](#-installation)
- [Structure du projet](#-structure-du-projet)
- [Configuration](#-configuration)
- [Utilisation](#-utilisation)
- [Base de donn√©es](#-base-de-donn√©es)
- [Analyse et rapports](#-analyse-et-rapports)
- [Tests](#-tests)
- [Utilitaires](#-utilitaires)
- [D√©pannage](#-d√©pannage)

## üéØ Vue d'ensemble

Le Stack Overflow Scraper est un syst√®me complet qui permet de :

1. **Extraire** des donn√©es de Stack Overflow (via API ou scraping web)
2. **Stocker** intelligemment en MongoDB avec gestion des doublons
3. **Analyser** les tendances, sentiments et patterns
4. **G√©n√©rer** des rapports d√©taill√©s automatiquement

### Workflow principal

```
Extraction ‚Üí Stockage ‚Üí Analyse ‚Üí Rapport
     ‚Üì           ‚Üì        ‚Üì         ‚Üì
  Questions   MongoDB   Trends   Reports
```

## üîÑ Fonctionnement Complet du Pipeline

### Vue d'ensemble du syst√®me

Le Stack Overflow Scraper & Analyzer ex√©cute un pipeline en **3 phases principales** avec g√©n√©ration automatique de rapports :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üì• PHASE 1     ‚îÇ    ‚îÇ  üíæ PHASE 2     ‚îÇ    ‚îÇ  üìä PHASE 3     ‚îÇ    ‚îÇ  üìÑ RAPPORT     ‚îÇ
‚îÇ  EXTRACTION     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  STOCKAGE       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ANALYSE        ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  G√âN√âRATION     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ API/Scraping  ‚îÇ    ‚îÇ ‚Ä¢ Filtering     ‚îÇ    ‚îÇ ‚Ä¢ NLP           ‚îÇ    ‚îÇ ‚Ä¢ Markdown      ‚îÇ
‚îÇ ‚Ä¢ Parsing       ‚îÇ    ‚îÇ ‚Ä¢ Upsert/Insert ‚îÇ    ‚îÇ ‚Ä¢ Trends        ‚îÇ    ‚îÇ ‚Ä¢ JSON Export   ‚îÇ
‚îÇ ‚Ä¢ Validation    ‚îÇ    ‚îÇ ‚Ä¢ Author Mgmt   ‚îÇ    ‚îÇ ‚Ä¢ Statistics    ‚îÇ    ‚îÇ ‚Ä¢ Metrics       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üì• PHASE 1 : Extraction des Donn√©es

#### üîç Sources d'extraction disponibles

**1. API Stack Overflow (Recommand√©)**
```bash
python main.py --use-api -n 1000
```
- **Avantages** : Rapide (15s pour 1000 questions), fiable, donn√©es structur√©es
- **Limitations** : 10k requ√™tes/jour sans cl√© API, 300 requ√™tes/jour avec cl√© gratuite
- **Technique** : Requ√™tes HTTPS vers `api.stackexchange.com`
- **Format** : JSON direct, pas de parsing HTML n√©cessaire

**2. Web Scraping (Selenium)**
```bash
python main.py -n 1000  # Mode par d√©faut
```
- **Avantages** : Illimit√©, contourne les quotas API
- **Limitations** : Plus lent (60s pour 1000 questions), d√©pendant du navigateur
- **Technique** : Chrome headless avec Selenium WebDriver
- **Format** : HTML parsing avec BeautifulSoup

#### üìä Structure des donn√©es extraites

Chaque question extraite contient :

```python
QuestionData {
    question_id: int,           # ID unique Stack Overflow
    title: str,                 # Titre de la question
    url: str,                  # URL compl√®te
    summary: str,              # Contenu/corps de la question
    tags: List[str],           # Technologies associ√©es
    author_name: str,          # Nom de l'auteur
    author_profile_url: str,   # Profil de l'auteur
    author_reputation: int,    # Points de r√©putation
    view_count: int,           # Nombre de vues
    vote_count: int,           # Score (votes up - votes down)
    answer_count: int,         # Nombre de r√©ponses
    publication_date: datetime # Date de publication
}
```

#### üéØ Filtrage et ciblage

**Filtrage par tags :**
```bash
# Technologies sp√©cifiques
python main.py -t python javascript react -n 1500

# Domaines sp√©cialis√©s  
python main.py -t "machine-learning" "data-science" -n 800
```

**Logique d'extraction :**
1. R√©cup√©ration des questions les plus r√©centes par d√©faut
2. Filtrage par tags si sp√©cifi√©s (op√©rateur OR entre les tags)
3. Parsing et validation des donn√©es
4. Enrichissement avec m√©tadonn√©es d'auteur

### üíæ PHASE 2 : Stockage Intelligent

#### üóÑÔ∏è Architecture de stockage

**Base MongoDB avec 3 collections :**

```
stackoverflow_data/
‚îú‚îÄ‚îÄ questions    (Collection principale - documents de questions)
‚îú‚îÄ‚îÄ authors      (M√©tadonn√©es des auteurs avec agr√©gations)
‚îî‚îÄ‚îÄ analysis     (R√©sultats d'analyses sauvegard√©s)
```

#### üîÑ Modes de stockage intelligents

**1. Mode `update` (d√©faut)**
```bash
python main.py --mode update
```
- **Comportement** : Upsert MongoDB avec `question_id` comme cl√©
- **Logic** : Met √† jour les questions existantes ET ajoute les nouvelles
- **Usage** : Maintenance quotidienne, actualisation des m√©triques
- **Technique** : `db.questions.replaceOne({question_id: X}, data, {upsert: true})`

**2. Mode `append-only`**
```bash
python main.py --mode append-only
```
- **Comportement** : Filtre les doublons AVANT insertion
- **Logic** : Ins√®re seulement les questions avec des `question_id` non-existants
- **Usage** : Collecte initiale, enrichissement sans doublons
- **Technique** : `existing_ids = db.questions.distinct('question_id')` puis filtrage

#### üë• Gestion intelligente des auteurs

**Tracking automatique des auteurs :**

```python
# Logique de gestion des auteurs lors du stockage
for question in new_questions:
    author_result = store_author(question.author_data)
    # Retourne : 'new', 'updated', ou 'skipped'
    
    if author_result == 'new':
        authors_new += 1
    elif author_result == 'updated':  
        authors_updated += 1
```

**Collection `authors` mise √† jour automatiquement :**
- `question_count` : Nombre de questions de cet auteur dans notre base
- `first_seen` / `last_seen` : Dates de premi√®re et derni√®re question collect√©e
- `reputation` : Mise √† jour si elle a chang√©

#### üìà M√©triques de stockage retourn√©es

```python
storage_result = {
    'questions_stored': 245,    # Nouvelles questions ajout√©es
    'authors_new': 12,          # Nouveaux auteurs d√©couverts  
    'authors_updated': 67,      # Auteurs avec r√©putation mise √† jour
    'execution_time': 2.45      # Temps de stockage en secondes
}
```

### üìä PHASE 3 : Analyse et Intelligence

#### üéØ Port√©es d'analyse configurables

**1. Analyse compl√®te (`--analysis-scope all`)**
```bash
python main.py --analysis-scope all
```
- **Donn√©es** : TOUTES les questions pr√©sentes dans la base
- **Usage** : Tendances globales, vision d'ensemble compl√®te
- **Performance** : Plus lent mais exhaustif
- **R√©sultat** : Analyse de 5000+ questions si base importante

**2. Analyse cibl√©e (`--analysis-scope new-only`)**
```bash
python main.py --analysis-scope new-only
```
- **Donn√©es** : Seulement les questions trait√©es lors de cette ex√©cution
- **Usage** : Analyse rapide des nouveaut√©s, optimisation performance
- **Performance** : Tr√®s rapide, adapt√© aux mises √† jour fr√©quentes
- **Logique intelligente** : Annulation automatique si aucune nouvelle question

#### üß† Moteurs d'analyse sp√©cialis√©s

**1. NLP Processor (Analyse de contenu)**

```python
# Analyses effectu√©es sur titles, summaries, et contenu combin√©
nlp_analysis = {
    'keywords_extraction': {
        'title_keywords': tfidf_analysis(titles),
        'summary_keywords': tfidf_analysis(summaries), 
        'combined_keywords': tfidf_analysis(titles + summaries)
    },
    'sentiment_analysis': {
        'title_sentiment': textblob_analysis(titles),
        'summary_sentiment': textblob_analysis(summaries),
        'combined_sentiment': textblob_analysis(combined_content)
    },
    'content_quality': {
        'summary_completeness': percentage_with_substantial_content,
        'technical_richness': technical_terms_ratio,
        'question_clarity': well_structured_questions_ratio
    }
}
```

**2. Trend Analyzer (Analyse des tendances)**

```python
# Calculs de croissance et d√©tection des tendances
trend_analysis = {
    'tag_trends': {
        'growth_calculation': (last_week_count / previous_week_count - 1) * 100,
        'trending_detection': growth_rate > threshold,
        'temporal_distribution': questions_per_time_period
    },
    'temporal_patterns': {
        'hourly_activity': peak_detection_by_hour,
        'daily_patterns': weekday_vs_weekend_analysis,
        'seasonal_trends': monthly_activity_analysis
    }
}
```

**3. Author Analyzer (Analyse des contributeurs)**

```python
# Statistiques sur les auteurs correspondant aux questions analys√©es
author_analysis = {
    'active_contributors': top_authors_by_question_count,
    'reputation_distribution': reputation_statistics,
    'activity_correlation': author_activity_vs_question_quality,
    'engagement_metrics': response_rates_by_author_tier
}
```

#### üìä Analyses statistiques avanc√©es

**M√©triques calcul√©es automatiquement :**

```python
comprehensive_stats = {
    'general_metrics': {
        'total_questions_analyzed': len(questions),
        'date_range': (earliest_date, latest_date),
        'avg_views_per_question': mean(view_counts),
        'response_rate': percentage_with_answers,
        'vote_distribution': score_statistics
    },
    'technical_metrics': {
        'tags_diversity': unique_tags_count,
        'complexity_indicators': technical_depth_analysis,
        'problem_categories': automated_categorization
    },
    'trend_metrics': {
        'growth_technologies': fastest_growing_tags,
        'declining_technologies': tags_with_negative_growth,
        'stability_index': technology_maturity_indicator
    }
}
```

### üìÑ G√©n√©ration Automatique de Rapports

#### üìù Rapports Markdown (toujours g√©n√©r√©s)

**Structure standardis√©e :**

```markdown
# üìä RAPPORT COMPLET - STACK OVERFLOW SCRAPER & ANALYZER

## üöÄ INFORMATIONS D'EX√âCUTION G√âN√âRALE
- Configuration utilis√©e et commande √©quivalente
- R√©sum√© des phases avec dur√©es et statuts

## üîç PHASE 1: EXTRACTION DES DONN√âES  
- M√©triques d'extraction (taux, questions/sec)
- Source utilis√©e (API/Scraping) et param√®tres

## üíæ PHASE 2: STOCKAGE EN BASE DE DONN√âES
- Op√©rations de stockage d√©taill√©es
- Gestion intelligente des auteurs (nouveaux/mis √† jour)
- Gestion des doublons et mode de stockage

## üìä PHASE 3: ANALYSE DES DONN√âES
- Configuration d'analyse (scope, dur√©e, p√©riode couverte)
- R√©sultats d√©taill√©s par cat√©gorie (si analyse effectu√©e)
- Ou statut d'analyse (d√©sactiv√©e/annul√©e) avec recommandations
```

**Gestion intelligente des statuts :**

1. **‚úÖ Analyse compl√®te** : Toutes les sections pr√©sentes avec donn√©es
2. **‚ùå Analyse d√©sactiv√©e** : Message explicatif avec suggestion
3. **‚ö†Ô∏è Analyse annul√©e** : Explication intelligente de l'optimisation

#### üîÑ Exports JSON (donn√©es structur√©es)

```python
# Sauvegarde dans output/analysis/
analysis_export = {
    'metadata': {
        'analysis_date': iso_timestamp,
        'total_questions_analyzed': count,
        'analysis_duration_seconds': duration,
        'scope': 'all' | 'new-only',
        'date_range': {'start': date1, 'end': date2}
    },
    'results': {
        'tag_trends': detailed_trend_data,
        'temporal_patterns': time_analysis_data,
        'content_analysis': nlp_results,
        'author_analysis': contributor_stats,
        'general_stats': comprehensive_metrics
    }
}
```

### üîß Logique Intelligente et Optimisations

#### üß† D√©cisions automatiques du syst√®me

**1. Optimisation des analyses**
```python
# Annulation intelligente pour performance
if analysis_scope == 'new-only' and questions_stored == 0:
    return "Analyse annul√©e - aucune nouvelle question"
    
# Limitation automatique des ressources  
if questions_count > 10000:
    enable_sampling = True
    log_warning("Large dataset - √©chantillonnage activ√©")
```

**2. Gestion des erreurs et r√©cup√©ration**
```python
# Retry automatique avec backoff
try:
    api_response = call_stackoverflow_api()
except RateLimitError:
    if retries < max_retries:
        sleep(exponential_backoff(retries))
        retry_request()
    else:
        fallback_to_web_scraping()
```

**3. Monitoring des performances**
```python
# M√©triques de performance automatiques
execution_metrics = {
    'extraction_rate': questions_extracted / extraction_time,
    'storage_rate': questions_stored / storage_time, 
    'analysis_rate': questions_analyzed / analysis_time,
    'total_pipeline_duration': end_time - start_time
}
```

#### ‚ö° Optimisations de performance

**Extraction :**
- Pool de connexions HTTP pour l'API
- Rate limiting intelligent avec respect des quotas
- Mise en cache des m√©tadonn√©es d'auteurs

**Stockage :**
- Op√©rations bulk MongoDB pour les insertions
- Index optimis√©s pour les requ√™tes fr√©quentes
- Transactions pour la coh√©rence des donn√©es

**Analyse :**
- Vectorisation NumPy pour les calculs TF-IDF
- Multiprocessing pour l'analyse de sentiment
- Mise en cache des r√©sultats co√ªteux

### üéØ Workflows Types d'Utilisation

#### üöÄ **Collecte initiale compl√®te**
```bash
# Nettoyage et collecte massive par technologie
python utils/clear_database.py
python main.py --use-api -n 2500 -t python --mode append-only
python main.py --use-api -n 1500 -t javascript --mode append-only
python main.py --use-api -n 1000 -t react vue.js --mode append-only
# R√©sultat : Base riche de ~5000 questions sans doublons
```

#### üîÑ **Maintenance quotidienne**
```bash
# Mise √† jour avec nouvelles questions + analyse compl√®te
python main.py --use-api -n 500 --mode update --analysis-scope all
# R√©sultat : Base actualis√©e + rapport de tendances globales
```

#### ‚ö° **Analyse rapide des nouveaut√©s**
```bash
# Collecte + analyse optimis√©e des nouveaut√©s seulement
python main.py --use-api -n 300 --mode append-only --analysis-scope new-only
# R√©sultat : Nouvelles donn√©es + analyse rapide cibl√©e
```

#### üéØ **Enrichissement cibl√©**
```bash
# Technologies √©mergentes sans analyse imm√©diate
python main.py --use-api -n 500 -t "machine-learning" --mode append-only --no-analysis
# Suivi par analyse compl√®te p√©riodique
python main.py --analysis-scope all --no-extraction
```

### üìä M√©triques et Monitoring

Le syst√®me fournit automatiquement des m√©triques d√©taill√©es √† chaque ex√©cution :

```
üìä Exemple de m√©triques d'ex√©cution
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîç Extraction    : 245 questions en 15.2s (16.1 questions/sec)
üíæ Stockage      : 187 nouvelles + 12 auteurs (2.1s, 94.3 op/sec) 
üìä Analyse       : 2,847 questions analys√©es en 8.7s
üìÑ Rapport       : Generated in output/reports/rapport_complet_*.md

üë• Auteurs       : 12 nouveaux, 45 mis √† jour, 67 inchang√©s
üè∑Ô∏è Technologies : 156 tags uniques, Python (23%), JS (18%), React (12%)
üìà Tendances     : React (+89%), TypeScript (+156%), Vue.js (+67%)
‚è∞ Performance   : Pipeline complet en 26.0s (9.4 questions/sec)
```

Ce pipeline complet assure une collecte intelligente, un stockage optimis√© et une analyse approfondie des donn√©es Stack Overflow avec une surveillance continue des performances et une adaptation automatique aux diff√©rents cas d'usage.

## ‚ú® Fonctionnalit√©s

### üîç Extraction de donn√©es
- **API Stack Overflow** : Extraction rapide et fiable (10k requ√™tes/jour gratuit)
- **Web Scraping** : Extraction via Selenium pour contournement des limites
- **Filtrage par tags** : Ciblage pr√©cis des technologies
- **Gestion des quotas** : Respect automatique des limites de l'API

### üíæ Stockage intelligent
- **Base MongoDB** : Stockage NoSQL optimis√© avec index
- **Modes de stockage** : `update` (mise √† jour) ou `append-only` (ajout uniquement)
- **Gestion des doublons** : D√©tection et filtrage automatique
- **Suivi des auteurs** : Collection s√©par√©e pour les m√©tadonn√©es des auteurs

### üìä Analyse avanc√©e
- **NLP (Natural Language Processing)** : Analyse de sentiment, extraction de mots-cl√©s
- **D√©tection de tendances** : Identification des technologies en croissance
- **Patterns temporels** : Analyse des patterns d'activit√© (heure, jour, mois)
- **Statistiques compl√®tes** : M√©triques d√©taill√©es sur l'ensemble des donn√©es

### üìà Reporting automatique
- **Rapports Markdown** : G√©n√©ration automatique de rapports complets
- **Analyses JSON** : Export des donn√©es d'analyse pour int√©gration
- **M√©triques d'ex√©cution** : Suivi des performances du syst√®me

## üöÄ Installation

### Pr√©requis

- **Python 3.8+** (test√© avec Python 3.12)
- **MongoDB** (local ou distant)
- **Google Chrome** (pour le scraping web)

### Installation des d√©pendances

```bash
# Cloner le repository
git clone https://github.com/pierre-mazard/so-scrapper.git
cd so-scrapper

# Installer les d√©pendances
pip install -r requirements.txt

# Installer les ressources NLTK (pour l'analyse NLP)
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
```

### Configuration initiale

1. **D√©marrer MongoDB** (si local) :
   ```bash
   # Windows
   net start MongoDB
   
   # Linux/macOS
   sudo systemctl start mongod
   # ou
   brew services start mongodb/brew/mongodb-community
   ```

2. **V√©rifier la connexion MongoDB** :
   ```bash
   python utils/check_mongodb.py
   ```

3. **Configuration optionnelle** :
   ```bash
   # Copier le fichier d'exemple
   cp .env.example .env
   # √âditer .env selon vos besoins
   ```

## üìÅ Structure du projet

```
so-scrapper/
‚îú‚îÄ‚îÄ üìÅ src/                     # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Package principal
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py             # Module de scraping (API + Web)
‚îÇ   ‚îú‚îÄ‚îÄ database.py            # Gestionnaire MongoDB
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py            # Moteur d'analyse NLP
‚îÇ   ‚îî‚îÄ‚îÄ config.py              # Gestion de la configuration
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                   # Suite de tests compl√®te
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Package de tests
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py            # Configuration pytest
‚îÇ   ‚îú‚îÄ‚îÄ test_*.py              # Tests unitaires par module
‚îÇ   ‚îú‚îÄ‚îÄ test_logger.py         # Syst√®me de logging des tests
‚îÇ   ‚îú‚îÄ‚îÄ analyze_logs.py        # Analyseur de logs de tests
‚îÇ   ‚îî‚îÄ‚îÄ logs/                  # Logs des tests
‚îÇ
‚îú‚îÄ‚îÄ üìÅ utils/                   # Utilitaires et scripts
‚îÇ   ‚îú‚îÄ‚îÄ check_mongodb.py       # Diagnostic MongoDB
‚îÇ   ‚îî‚îÄ‚îÄ clear_database.py      # Nettoyage de la base
‚îÇ
‚îú‚îÄ‚îÄ üìÅ output/                  # R√©sultats g√©n√©r√©s
‚îÇ   ‚îú‚îÄ‚îÄ analysis/              # Analyses JSON
‚îÇ   ‚îú‚îÄ‚îÄ reports/               # Rapports Markdown
‚îÇ   ‚îî‚îÄ‚îÄ visualizations/        # Graphiques 
‚îÇ
‚îú‚îÄ‚îÄ üìÅ logs/                    # Logs d'ex√©cution
‚îÇ   ‚îî‚îÄ‚îÄ scraper.log            # Log principal
‚îÇ
‚îú‚îÄ‚îÄ üìÑ main.py                  # Point d'entr√©e principal
‚îú‚îÄ‚îÄ üìÑ run_tests.py             # Script de lancement des tests
‚îú‚îÄ‚îÄ üìÑ analysis_notebook.ipynb # Notebook Jupyter d'analyse
‚îú‚îÄ‚îÄ üìÑ config.json             # Configuration par d√©faut
‚îú‚îÄ‚îÄ üìÑ .env                    # Variables d'environnement
‚îú‚îÄ‚îÄ üìÑ requirements.txt        # D√©pendances Python
‚îú‚îÄ‚îÄ üìÑ pytest.ini             # Configuration des tests
‚îî‚îÄ‚îÄ üìÑ README.md               # Documentation (ce fichier)
```

### Modules principaux

| Module | Responsabilit√© | Classes principales |
|--------|---------------|-------------------|
| `scraper.py` | Extraction de donn√©es | `StackOverflowScraper`, `QuestionData` |
| `database.py` | Persistance MongoDB | `DatabaseManager` |
| `analyzer.py` | Analyse des donn√©es | `DataAnalyzer`, `NLPProcessor`, `TrendAnalyzer` |
| `config.py` | Configuration | `Config`, `ScraperConfig`, `DatabaseConfig` |

## ‚öôÔ∏è Configuration

Le syst√®me utilise une configuration hi√©rarchique par ordre de priorit√© :

1. **Variables d'environnement** (priorit√© maximale)
2. **Fichier `.env`** 
3. **Fichier `config.json`**
4. **Valeurs par d√©faut**

### Configuration MongoDB (`config.json`)

```json
{
  "database": {
    "host": "localhost",
    "port": 27017,
    "name": "stackoverflow_data",
    "collection": "questions",
    "max_pool_size": 10,
    "timeout_ms": 30000
  }
}
```

### Configuration API Stack Overflow

```json
{
  "api": {
    "key": "",              // Optionnel - 10k requ√™tes/jour sans cl√©
    "rate_limit": 300,      // Requ√™tes par seconde
    "quota_max": 10000,     // Quota journalier
    "site": "stackoverflow"
  }
}
```

### Variables d'environnement (`.env`)

```bash
# MongoDB
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=stackoverflow_data

# Logging
LOG_LEVEL=INFO

# Scraper
SCRAPER_HEADLESS=true
SCRAPER_DELAY=2

# Analysis
ENABLE_NLP=true
ENABLE_SENTIMENT_ANALYSIS=true
```

## üéØ Utilisation

### Commande de base

```bash
python main.py
```

**Comportement par d√©faut :**
- Extrait 300 questions via scraping web
- Stocke en mode `update` (met √† jour les existantes et ajoute les nouvelles)
- Effectue une analyse compl√®te
- G√©n√®re un rapport automatique

### Syntaxe compl√®te

```bash
python main.py [OPTIONS]
```

### üìù Param√®tres et options

| Option | Raccourci | Type | D√©faut | Description |
|--------|-----------|------|--------|-------------|
| `--max-questions` | `-n` | int | 300 | Nombre max de questions √† extraire |
| `--tags` | `-t` | list | None | Tags √† filtrer (ex: python javascript) |
| `--use-api` | | flag | False | Utiliser l'API au lieu du scraping |
| `--no-analysis` | | flag | False | D√©sactiver compl√®tement l'analyse des donn√©es |
| `--log-level` | | choice | INFO | Niveau de logging (DEBUG/INFO/WARNING/ERROR) |
| `--mode` | | choice | update | Mode de stockage (update/append-only) |
| `--analysis-scope` | | choice | all | Port√©e de l'analyse (all/new-only) |

### Modes de stockage

#### üîÑ Mode `update` (d√©faut)
```bash
python main.py --mode update
```
- **Comportement** : Met √† jour les questions existantes et ajoute les nouvelles
- **Usage** : Maintenance r√©guli√®re, actualisation des donn√©es
- **Technique** : Utilise l'upsert MongoDB sur `question_id`

#### ‚ûï Mode `append-only`
```bash
python main.py --mode append-only
```
- **Comportement** : Ajoute seulement les nouvelles questions, ignore les doublons
- **Usage** : Enrichissement de la base, √©viter les doublons
- **Technique** : Filtre les IDs existants avant insertion

### Port√©es d'analyse

#### üåê Mode `all` (d√©faut)
```bash
python main.py --analysis-scope all
```
- **Comportement** : Analyse toutes les questions pr√©sentes dans la base de donn√©es
- **Usage** : Analyse compl√®te des tendances globales
- **Technique** : R√©cup√®re et analyse toutes les questions stock√©es

#### üéØ Mode `new-only`
```bash
python main.py --analysis-scope new-only
```
- **Comportement** : Analyse seulement les questions nouvellement ajout√©es/mises √† jour
- **Usage** : Analyse rapide des nouvelles tendances, optimisation des performances
- **Technique** : Filtre et analyse uniquement les questions trait√©es lors de l'ex√©cution courante
- **Note** : Si aucune nouvelle question, l'analyse est automatiquement annul√©e

#### üí° Combinaisons utiles
```bash
# Ajout de nouvelles donn√©es + analyse compl√®te
python main.py --mode append-only --analysis-scope all

# Ajout de nouvelles donn√©es + analyse des nouveaut√©s seulement
python main.py --mode append-only --analysis-scope new-only

# Mise √† jour + analyse des changements seulement
python main.py --mode update --analysis-scope new-only

# Collecte sans analyse imm√©diate (optimisation performance)
python main.py --use-api -n 2000 --no-analysis
```

#### ‚ö†Ô∏è Mode d'analyse d√©sactiv√©
```bash
python main.py --no-analysis
```
- **Comportement** : Effectue uniquement l'extraction et le stockage, aucune analyse
- **Usage** : Collecte massive de donn√©es sans traitement imm√©diat
- **Rapport** : Un rapport d'ex√©cution est quand m√™me g√©n√©r√© avec le statut "Analyse d√©sactiv√©e"
- **Note** : Permet d'optimiser les performances lors de collectes importantes

### üí° Exemples d'utilisation

#### 1. Extraction basique
```bash
# 300 questions par d√©faut
python main.py

# 1000 questions via scraping
python main.py -n 1000
```

#### 2. Extraction via API
```bash
# Plus rapide et fiable
python main.py --use-api -n 2500

# API avec tags sp√©cifiques
python main.py --use-api -t python javascript -n 1000
```

#### 3. Gestion des doublons
```bash
# Mode append-only : √©vite les doublons
python main.py -n 2500 --use-api --mode append-only

# Enrichissement progressif par tags
python main.py -t python --mode append-only
python main.py -t react --mode append-only
python main.py -t vue.js --mode append-only
```

#### 4. Extraction cibl√©e
```bash
# Questions Python seulement
python main.py -t python -n 1000

# Multiple tags
python main.py -t python javascript react -n 1500

# Technologies frontend
python main.py -t html css javascript react vue.js --use-api
```

#### 5. Modes avanc√©s
```bash
# Extraction sans analyse (plus rapide)
python main.py -n 1000 --no-analysis

# Mode debug complet
python main.py --log-level DEBUG -n 100

# Production : API + append-only + analyse
python main.py --use-api -n 2500 --mode append-only
```

#### 6. Modes d'analyse optimis√©s
```bash
# Collecte + analyse compl√®te (d√©faut)
python main.py --use-api -n 1000 --analysis-scope all

# Collecte + analyse rapide des nouveaut√©s seulement
python main.py --use-api -n 1000 --analysis-scope new-only

# Mode append-only + analyse des nouvelles questions
python main.py --mode append-only --analysis-scope new-only -n 500

# Mise √† jour + analyse compl√®te pour recalculer les tendances
python main.py --mode update --analysis-scope all

# Mode √©conome : collecte sans analyse imm√©diate
python main.py --use-api -n 2000 --no-analysis
# ‚Üí G√©n√®re quand m√™me un rapport d'ex√©cution avec statut "Analyse d√©sactiv√©e"

# Cas d'analyse annul√©e automatiquement
python main.py --mode append-only --analysis-scope new-only -n 100
# ‚Üí Si aucune nouvelle question, l'analyse est annul√©e intelligemment
# ‚Üí Le rapport indique "Analyse annul√©e - Aucune nouvelle question"
```

#### 7. Workflows sp√©cialis√©s
```bash
# Collecte initiale massive
python main.py --use-api -n 2500 --mode append-only --no-analysis

# Mise √† jour quotidienne
python main.py --use-api -n 500 --mode update

# Analyse de technologies sp√©cifiques
python main.py -t "machine-learning" "artificial-intelligence" --use-api
```

## ÔøΩÔ∏è Base de donn√©es

### Architecture MongoDB

Le syst√®me utilise MongoDB avec une architecture optimis√©e pour les donn√©es Stack Overflow :

```
Database: stackoverflow_data
‚îú‚îÄ‚îÄ üìÑ questions     (Collection principale)
‚îú‚îÄ‚îÄ üìÑ authors       (M√©tadonn√©es des auteurs)  
‚îî‚îÄ‚îÄ üìÑ analysis      (R√©sultats d'analyses)
```

### Collection `questions`

**Structure d'un document :**

```javascript
{
  _id: ObjectId("..."),
  question_id: 79727532,                    // ID Stack Overflow (unique)
  title: "How to use async/await in Python?",
  url: "https://stackoverflow.com/questions/...",
  summary: "I'm trying to understand...",   // Contenu de la question
  tags: ["python", "async-await", "asyncio"],
  
  // Auteur
  author_name: "PythonDev",
  author_profile_url: "https://stackoverflow.com/users/...",
  author_reputation: 5420,
  
  // M√©triques
  view_count: 1250,
  vote_count: 15,
  answer_count: 3,
  
  // Dates
  publication_date: ISODate("2025-08-06T10:30:00Z"),
  stored_at: ISODate("2025-08-07T11:45:00Z"),
  last_updated: ISODate("2025-08-07T11:45:00Z")
}
```

**Index configur√©s :**
- `question_id` (unique) - Cl√© primaire m√©tier
- `publication_date` (descendant) - Tri chronologique
- `tags` - Recherche par technologie
- `title + summary` (text) - Recherche textuelle compl√®te
- `tags + publication_date` (compos√©) - Requ√™tes complexes

### Collection `authors`

```javascript
{
  _id: ObjectId("..."),
  author_name: "PythonDev",               // Nom d'utilisateur (unique)
  profile_url: "https://stackoverflow.com/users/...",
  reputation: 5420,
  question_count: 12,                     // Nombre de questions dans notre base
  first_seen: ISODate("2025-08-06T..."), // Premi√®re question collect√©e
  last_seen: ISODate("2025-08-07T...")   // Derni√®re question collect√©e
}
```

### Collection `analysis`

```javascript
{
  _id: ObjectId("..."),
  analysis_type: "comprehensive_trend_analysis",
  analysis_date: ISODate("2025-08-07T..."),
  
  // M√©tadonn√©es
  metadata: {
    total_questions_analyzed: 5000,
    analysis_duration: 7.85,
    date_range: {
      start: "2025-05-28T08:54:25",
      end: "2025-08-07T11:26:54"
    }
  },
  
  // R√©sultats d√©taill√©s
  results: {
    tag_trends: { ... },           // Tendances des technologies
    temporal_patterns: { ... },    // Patterns temporels
    content_analysis: { ... },     // Analyse NLP
    author_analysis: { ... },      // Statistiques auteurs
    general_stats: { ... }         // M√©triques g√©n√©rales
  }
}
```

### M√©triques de performance

- **Questions** : ~557 bytes/document en moyenne
- **Auteurs** : ~193 bytes/document en moyenne
- **Analyses** : ~12KB/document (tr√®s d√©taill√©es)

### Utilisation des utilitaires

```bash
# Diagnostic complet de la base
python utils/check_mongodb.py

# Nettoyage complet (‚ö†Ô∏è DESTRUCTIF)
python utils/clear_database.py
```

## üìä Analyse et rapports

### Moteur d'analyse

Le syst√®me d'analyse est compos√© de plusieurs modules sp√©cialis√©s :

#### üîç NLP Processor
- **Preprocessing** : Nettoyage et normalisation des textes
- **Keywords extraction** : TF-IDF pour identifier les termes importants (titles, summaries, contenu combin√©)
- **Sentiment analysis** : Analyse du sentiment avec TextBlob (titles, summaries, contenu combin√©)
- **Content quality analysis** : M√©triques de qualit√© du contenu (compl√©tude, richesse technique, clart√©)
- **Vectorisation** : Pr√©paration pour l'analyse de clustering

#### üìà Trend Analyzer
- **Tag trends** : Croissance des technologies par p√©riode
- **Temporal patterns** : Patterns d'activit√© (heure, jour, mois)
- **Growth rates** : Calcul des taux de croissance
- **Peak detection** : Identification des pics d'activit√©

#### üéØ Data Analyzer (Principal)
- **Orchestration** : Coordonne tous les types d'analyse
- **Content analysis** : Analyse des titres et r√©sum√©s
- **Author analysis** : Statistiques sur les auteurs actifs
- **General stats** : M√©triques globales

### Types d'analyses effectu√©es

#### 1. Analyse des tendances des tags
```python
{
  "trending_tags": [
    {
      "tag": "react",
      "total_questions": 176,
      "growth_rate": 98.3,
      "last_week": 56,
      "last_month": 117
    }
  ],
  "top_tags": [...]
}
```

#### 2. Patterns temporels
```python
{
  "hourly_patterns": {
    "peak_hour": 17,          // 17h = pic d'activit√©
    "votes_mean": {...},      // Moyennes de votes par heure
    "answers_mean": {...}     // Moyennes de r√©ponses par heure
  },
  "daily_patterns": {...},   // Patterns par jour de la semaine
  "monthly_patterns": {...}  // Patterns par mois
}
```

#### 3. Analyse de contenu NLP
```python
{
  "title_keywords": [
    ["python", 0.058],        // Mots-cl√©s des titres avec scores TF-IDF
    ["error", 0.048],
    ["function", 0.028]
  ],
  "summary_keywords": [
    ["trying", 0.045],        // Mots-cl√©s des r√©sum√©s
    ["understand", 0.038],
    ["implement", 0.035]
  ],
  "combined_keywords": [      // Analyse du contenu complet (titre + r√©sum√©)
    ["python", 0.062],
    ["function", 0.041],
    ["error", 0.038]
  ],
  "title_sentiment": {
    "positive": 443,
    "negative": 450,
    "neutral": 4107,
    "average": -0.0045        // L√©g√®rement n√©gatif (probl√®mes techniques)
  },
  "summary_sentiment": {      // Sentiment des r√©sum√©s
    "positive": 612,
    "negative": 298,
    "neutral": 4090,
    "average": 0.0123         // Plus positif (explications d√©taill√©es)
  },
  "content_quality": {        // Nouvelle analyse de qualit√©
    "summary_completeness": 78.5,     // % de questions avec r√©sum√© substantiel
    "content_richness": {
      "technical_word_ratio": 23.4,   // % de mots techniques
      "avg_words_per_question": 42.8,
      "technical_term_count": 1847
    },
    "technical_depth": 15.6,          // % de questions avec termes avanc√©s
    "question_clarity": {
      "clear_questions_ratio": 67.8,  // % de questions bien structur√©es
      "questions_with_context": 3387
    }
  }
}
```

### Rapports g√©n√©r√©s

#### üìÑ Rapport Markdown (`output/reports/`)
- **R√©sum√© ex√©cutif** avec m√©triques cl√©s
- **Analyse d√©taill√©e** par cat√©gorie (si l'analyse a √©t√© effectu√©e)
- **Tableaux** des tendances et statistiques
- **Recommandations** bas√©es sur les donn√©es
- **G√©n√©ration syst√©matique** : Un rapport est toujours g√©n√©r√©, m√™me si l'analyse est d√©sactiv√©e ou annul√©e

#### üîÑ Statuts d'analyse dans les rapports
- **‚úÖ Analyse compl√®te** : Toutes les sections d'analyse sont pr√©sentes
- **‚ùå Analyse d√©sactiv√©e** : Rapport avec informations d'ex√©cution uniquement
  - Message : "Analyse d√©sactiv√©e par l'utilisateur (--no-analysis)"
  - Suggestion : "Pour activer l'analyse, retirez l'option `--no-analysis`"
- **‚ö†Ô∏è Analyse annul√©e** : Analyse intelligemment annul√©e pour optimiser les performances
  - Message : "Aucune nouvelle question √† analyser"
  - Suggestion : "Utilisez `--analysis-scope all` pour forcer l'analyse de toutes les questions"

#### üìä Donn√©es JSON (`output/analysis/`)
- **Format structur√©** pour int√©gration
- **Toutes les m√©triques** calcul√©es
- **M√©tadonn√©es** d'ex√©cution
- **Pr√™t pour visualisation**

### Exemples de m√©triques

```
üìä M√©triques d'exemple (base de 5000 questions)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ Technologies top 5 : Python (2000), JavaScript (916), HTML (210)
‚Ä¢ Taux de r√©ponses : 54.3% des questions ont des r√©ponses
‚Ä¢ Auteurs actifs : 4900 auteurs uniques
‚Ä¢ P√©riode couverte : 2.5 mois
‚Ä¢ Pic d'activit√© : Mardi 17h
‚Ä¢ Sentiment moyen : L√©g√®rement n√©gatif (-0.005)
‚Ä¢ Croissance : React (+98%), TypeScript (+140%)
```

## üß™ Tests

### Architecture de tests

Le projet dispose d'une suite de tests compl√®te avec **70 tests unitaires** couvrant tous les modules :

```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Configuration pytest + plugin logging
‚îú‚îÄ‚îÄ test_analyzer.py         # Tests du moteur d'analyse (22 tests)
‚îú‚îÄ‚îÄ test_config.py           # Tests de configuration (20 tests)  
‚îú‚îÄ‚îÄ test_database.py         # Tests MongoDB (16 tests)
‚îú‚îÄ‚îÄ test_scraper.py          # Tests d'extraction (12 tests)
‚îú‚îÄ‚îÄ test_logger.py           # Syst√®me de logging des tests
‚îú‚îÄ‚îÄ analyze_logs.py          # Analyseur de r√©sultats de tests
‚îî‚îÄ‚îÄ logs/                    # Logs d√©taill√©s des tests
```

### Lancement des tests

#### üöÄ Ex√©cution standard
```bash
# Tous les tests avec rapport automatique
python run_tests.py

# Tests uniquement
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=src --cov-report=html
```

#### üéØ Tests sp√©cifiques
```bash
# Module sp√©cifique
pytest tests/test_scraper.py -v

# Test particulier
pytest tests/test_database.py::TestDatabaseManager::test_store_questions -v

# Tests par marqueur
pytest tests/ -m "not slow" -v
```

#### üîç Tests avec options avanc√©es
```bash
# Mode debug avec logs d√©taill√©s
pytest tests/ -v --log-cli --log-cli-level=DEBUG

# Tests d'int√©gration uniquement
pytest tests/ -m integration -v

# Tests rapides (sans int√©gration)
pytest tests/ -m "not integration" -v
```

### Rapports de tests

#### üìä Rapport automatique
Le script `run_tests.py` g√©n√®re automatiquement :

```
output/reports/rapport_tests_YYYYMMDD_HHMMSS.md
```

**Contenu du rapport :**
- ‚úÖ **R√©sum√© ex√©cutif** : 69/70 tests r√©ussis (98.6%)
- üìä **Statistiques d√©taill√©es** par module
- ‚è±Ô∏è **Temps d'ex√©cution** : ~102 secondes
- üîç **Tests √©chou√©s** avec d√©tails des erreurs
- üí° **Recommandations** pour corriger les probl√®mes

#### üìã Exemple de r√©sultats
```
üß™ RAPPORT DE TESTS - STACK OVERFLOW SCRAPER
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä R√âSUM√â EX√âCUTIF
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ Tests totaux : 70
‚Ä¢ R√©ussis : 69 (98.6%)
‚Ä¢ √âchou√©s : 0 (0.0%)  
‚Ä¢ Ignor√©s : 1 (1.4%)
‚Ä¢ Dur√©e : 101.61s

üìà R√âSULTATS PAR MODULE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ test_analyzer.py : 22/22 ‚úÖ
‚Ä¢ test_config.py : 20/20 ‚úÖ
‚Ä¢ test_database.py : 15/16 ‚úÖ (1 ignor√©)
‚Ä¢ test_scraper.py : 12/12 ‚úÖ
```

### Configuration des tests

#### üìÅ `pytest.ini`
```ini
[tool:pytest]
addopts = 
    -v --tb=short
    --log-cli=true
    --log-cli-level=INFO
    --disable-warnings

markers =
    slow: tests lents (int√©gration)
    integration: tests d'int√©gration
    unit: tests unitaires
```

#### üîß Fixtures disponibles
- **`db_manager`** : Gestionnaire de base mock√©e
- **`sample_questions`** : Donn√©es de test
- **`config`** : Configuration de test
- **`nlp_processor`** : Processeur NLP mock√©

### Tests d'int√©gration

```bash
# Tests avec vraie base MongoDB (n√©cessite MongoDB actif)
pytest tests/ -m integration -v

# Test complet bout-en-bout
pytest tests/test_database.py::TestDatabaseIntegration -v
```

‚ö†Ô∏è **Note** : Les tests d'int√©gration n√©cessitent MongoDB actif et peuvent modifier la base de test.

## üõ†Ô∏è Utilitaires

### Scripts de maintenance

#### üîç `utils/check_mongodb.py`
**Diagnostic complet de MongoDB**

```bash
python utils/check_mongodb.py
```

**Fonctionnalit√©s :**
- ‚úÖ Test de connexion MongoDB
- üìä Informations du serveur (version, plateforme)
- üìã Liste des bases de donn√©es et collections
- üîç **Analyse d√©taill√©e des collections** :
  - Structure des documents avec types de donn√©es
  - Statistiques : taille, nombre de documents, moyennes
  - Index configur√©s avec d√©tails
  - Plages de dates et m√©triques num√©riques
- üíæ Test d'√©criture/lecture
- ‚ö†Ô∏è D√©tection de probl√®mes courants

**Exemple de sortie :**
```
üîç V√âRIFICATION DE LA CONFIGURATION MONGODB
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìç URL : mongodb://localhost:27017/
üìç Base : stackoverflow_data
‚úÖ MongoDB connect√© avec succ√®s!
üìä Version MongoDB: 8.0.12

üìã Collections dans 'stackoverflow_data':
   üìÑ questions (5,581 documents)
   üìÉ authors (4,900 documents)  
   üìÉ analysis (5 documents)

üîç ANALYSE D√âTAILL√âE DES COLLECTIONS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìÑ Collection: questions
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìä Nombre de documents: 5,581
üîç Structure des documents:
   ‚Ä¢ question_id         : int    (ex: 79726836)
   ‚Ä¢ title              : str    (ex: Best project structure...)
   ‚Ä¢ tags               : Array[str] (ex: ['python', 'api'])
   ‚Ä¢ view_count         : int    (ex: 62)
   ‚Ä¢ publication_date   : DateTime (ex: 2025-08-06 06:44)
üìà Statistiques:
   üíæ Taille: 2.97 MB
   üìÖ publication_date: 2025-05-28 08:54 ‚Üí 2025-08-06 17:44
   üî¢ view_count: min=5, max=3856, avg=67.4
üóÇÔ∏è Index:
   üóÇÔ∏è question_id_1: question_id:1 (UNIQUE)
   üóÇÔ∏è publication_date_1: publication_date:1
   üóÇÔ∏è tags_1: tags:1
```

#### üóëÔ∏è `utils/clear_database.py`
**Nettoyage complet de la base**

```bash
python utils/clear_database.py
```

**‚ö†Ô∏è ATTENTION :** Op√©ration destructive irr√©versible !

**Protection :** Demande confirmation explicite (taper "OUI")

**Supprime :**
- Toutes les questions
- Tous les auteurs
- Toutes les analyses
- Tous les index personnalis√©s

#### üìä `tests/analyze_logs.py`
**Analyseur de logs de tests**

```bash
python tests/analyze_logs.py --show
```

**G√©n√®re :**
- Rapport d√©taill√© des r√©sultats de tests
- Statistiques de performance par test
- Analyse des erreurs et √©checs
- Recommandations d'am√©lioration

### Scripts d'ex√©cution

#### üöÄ `run_tests.py`
**Lanceur de tests avec rapport automatique**

```bash
python run_tests.py
```

**Fonctionnalit√©s :**
- Ex√©cution compl√®te de la suite de tests
- G√©n√©ration automatique de rapport Markdown
- Logging d√©taill√© dans `tests/logs/`
- Statistiques de performance
- Code de sortie appropri√© pour CI/CD

#### üìì `analysis_notebook.ipynb`
**Notebook Jupyter pour analyse interactive**

```bash
jupyter notebook analysis_notebook.ipynb
```

**Contenu :**
- Connexion √† la base MongoDB
- Analyses interactives des donn√©es
- Visualisations personnalis√©es
- Exp√©rimentation avec les donn√©es

## üîß D√©pannage

### Probl√®mes courants et solutions

#### 1. üîÑ Gestion des doublons

**Probl√®me :** Moins de questions que pr√©vu apr√®s extraction

```bash
# Diagnostic
python utils/check_mongodb.py  # V√©rifier le nombre actuel

# Solutions
# Option 1: Mode append-only (recommand√©)
python main.py -n 2500 --use-api --mode append-only

# Option 2: Enrichissement progressif par tags
python main.py -t python --mode append-only
python main.py -t javascript --mode append-only
python main.py -t react --mode append-only

# Option 3: Vider et recommencer
python utils/clear_database.py
python main.py -n 5000 --use-api
```

#### 2. üóÑÔ∏è Erreurs MongoDB

**Probl√®me :** Connexion MongoDB √©chou√©e

```bash
# Diagnostic complet
python utils/check_mongodb.py

# Solutions par OS
# Windows
net start MongoDB

# Linux/Ubuntu
sudo systemctl start mongod
sudo systemctl status mongod

# macOS
brew services start mongodb/brew/mongodb-community

# Docker
docker run -d -p 27017:27017 mongo:latest
```

**Probl√®me :** Base corrompue ou probl√®mes de performance

```bash
# Nettoyage complet (‚ö†Ô∏è destructif)
python utils/clear_database.py

# V√©rification apr√®s nettoyage
python utils/check_mongodb.py
```

#### 3. üåê Erreurs API Stack Overflow

**Probl√®me :** Quota API d√©pass√©

```bash
# Basculer vers scraping web
python main.py -n 500  # sans --use-api

# R√©duire la fr√©quence
python main.py --use-api -n 50  # petites quantit√©s

# Obtenir une cl√© API (10k/jour gratuit)
# √âditer config.json:
{
  "api": {
    "key": "votre_cl√©_ici"
  }
}
```

**Probl√®me :** Timeouts ou erreurs r√©seau

```bash
# Augmenter les timeouts dans config.json
{
  "scraper": {
    "timeout": 60,
    "retry_count": 5
  }
}

# Mode debug pour diagnostiquer
python main.py --log-level DEBUG -n 10
```

#### 4. üîç Erreurs de scraping web

**Probl√®me :** ChromeDriver obsol√®te

```bash
# Mise √† jour automatique
pip install --upgrade webdriver-manager

# Installation manuelle si n√©cessaire
# T√©l√©charger depuis: https://chromedriver.chromium.org/
```

**Probl√®me :** Chrome non trouv√©

```bash
# V√©rifier l'installation de Chrome
google-chrome --version  # Linux
chrome --version         # macOS

# Configuration headless dans .env
SCRAPER_HEADLESS=true
```

#### 5. üß† Erreurs d'analyse NLP

**Probl√®me :** Ressources NLTK manquantes

```bash
# Installation compl√®te des ressources NLTK
python -c "
import nltk
nltk.download('punkt')
nltk.download('stopwords') 
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
"
```

**Probl√®me :** Erreurs de m√©moire lors de l'analyse

```bash
# R√©duire la taille des donn√©es √† analyser
python main.py -n 1000 --use-api  # au lieu de 5000

# D√©sactiver l'analyse temporairement
python main.py -n 2500 --no-analysis
```

#### 6. üß™ Erreurs de tests

**Probl√®me :** Tests d'int√©gration √©chouent

```bash
# V√©rifier MongoDB pour les tests d'int√©gration
python utils/check_mongodb.py

# Lancer seulement les tests unitaires
pytest tests/ -m "not integration" -v

# Nettoyer les logs de tests
rm -rf tests/logs/*
```

**Probl√®me :** Tests lents

```bash
# Tests rapides seulement
pytest tests/ -m "not slow" -v

# Tests en parall√®le (si pytest-xdist install√©)
pytest tests/ -n auto
```

### üìù Logging et d√©bogage

#### Niveaux de logging disponibles

```bash
# Debug complet (tr√®s verbeux)
python main.py --log-level DEBUG

# Informations normales (recommand√©)
python main.py --log-level INFO

# Avertissements seulement
python main.py --log-level WARNING

# Erreurs critiques seulement
python main.py --log-level ERROR
```

#### Fichiers de logs

```bash
# Log principal de l'application
tail -f logs/scraper.log

# Logs des tests
ls tests/logs/
cat tests/logs/test_run_*.log
```

### üö® Probl√®mes de performance

#### Extraction lente

```bash
# Pr√©f√©rer l'API au scraping web
python main.py --use-api -n 2500  # ~15s vs ~60s

# R√©duire les d√©lais de scraping (risqu√©)
# √âditer config.json:
{
  "scraper": {
    "delay_between_requests": 1  # au lieu de 2
  }
}
```

#### Base MongoDB lente

```bash
# V√©rifier les index
python utils/check_mongodb.py

# Requ√™tes optimis√©es - v√©rifier les patterns d'usage
# Les index sont configur√©s automatiquement
```

### üîÑ Workflows de r√©cup√©ration

#### R√©cup√©ration apr√®s probl√®me majeur

```bash
# 1. Diagnostic complet
python utils/check_mongodb.py

# 2. Sauvegarde si possible
mongodump --db stackoverflow_data --out backup/

# 3. Nettoyage si n√©cessaire  
python utils/clear_database.py

# 4. Re-collecte progressive
python main.py --use-api -n 1000 --mode append-only
python main.py -t python --use-api --mode append-only
python main.py -t javascript --use-api --mode append-only

# 5. V√©rification finale
python utils/check_mongodb.py
```

#### Test de sant√© rapide

```bash
# Test de bout-en-bout minimal
python main.py -n 10 --use-api --log-level DEBUG

# V√©rification de l'analyse
python main.py -n 50 --use-api --mode append-only
```

### üí° Conseils d'optimisation

1. **Pour la collecte de donn√©es :**
   - Utilisez l'API (`--use-api`) autant que possible
   - Mode `append-only` pour √©viter les doublons
   - Collecte par tags sp√©cifiques pour cibler

2. **Pour les performances :**
   - MongoDB avec SSD recommand√©
   - 8GB+ RAM pour analyses importantes
   - Python 3.9+ pour meilleures performances

3. **Pour la maintenance :**
   - Ex√©cutez `check_mongodb.py` r√©guli√®rement
   - Sauvegardez avant les gros changements
   - Utilisez les logs pour diagnostiquer

### üìû Support

En cas de probl√®me persistant :

1. **V√©rifiez les logs** : `logs/scraper.log`
2. **Ex√©cutez le diagnostic** : `python utils/check_mongodb.py`
3. **Testez en mode minimal** : `python main.py -n 10 --log-level DEBUG`
4. **Consultez les issues GitHub** du projet

## üöÄ Workflow de production recommand√©

### 1. **Collecte initiale massive**
```bash
# Nettoyage et pr√©paration
python utils/clear_database.py
python utils/check_mongodb.py

# Collecte par technologie (mode append-only)
python main.py --use-api -n 2500 -t python --mode append-only
python main.py --use-api -n 1500 -t javascript --mode append-only  
python main.py --use-api -n 1000 -t react --mode append-only
python main.py --use-api -n 1000 -t vue.js --mode append-only

# V√©rification finale
python utils/check_mongodb.py
```

### 2. **Maintenance quotidienne**
```bash
# Mise √† jour des questions existantes + nouvelles
python main.py --use-api -n 500 --mode update

# Analyse compl√®te
# (l'analyse est automatique avec la commande ci-dessus)
```

### 3. **Enrichissement p√©riodique**
```bash
# Nouvelles technologies √©mergentes
python main.py --use-api -n 500 -t "machine-learning" --mode append-only
python main.py --use-api -n 500 -t "artificial-intelligence" --mode append-only

# Langages sp√©cialis√©s
python main.py --use-api -n 300 -t rust --mode append-only
python main.py --use-api -n 300 -t go --mode append-only
```

### 4. **Monitoring et maintenance**
```bash
# V√©rification hebdomadaire
python utils/check_mongodb.py

# Tests mensuels
python run_tests.py

# Analyse de performance
# Consulter output/reports/ pour les tendances
```

---
